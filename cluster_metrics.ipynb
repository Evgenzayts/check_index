{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import re"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.preprocessing import StandardScaler\n", "from sklearn.manifold import TSNE\n", "from sklearn.cluster import MeanShift, estimate_bandwidth, DBSCAN, AffinityPropagation\n", "from sklearn.metrics import (\n", "    silhouette_score,\n", "    davies_bouldin_score,\n", "    calinski_harabasz_score,\n", "    adjusted_rand_score\n", ")\n", "from sklearn.metrics.pairwise import euclidean_distances\n", "from sklearn.neighbors import NearestNeighbors\n", "from kneed import KneeLocator"]}, {"cell_type": "markdown", "metadata": {}, "source": ["=== \u041a\u043e\u043d\u0441\u0442\u0430\u043d\u0442\u044b ==="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["PARQUET_PATH      = \"data15.parquet\"\n", "PLOTS_DIR         = \"analysis_plots\"\n", "RANDOM_STATE      = 42\n", "TSNE_SAMPLE_SIZE  = 3000\n", "CORR_THRESHOLD    = 0.8"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["MS_DBSCAN_ATTEMPTS = 7   # \u0447\u0438\u0441\u043b\u043e \u043f\u043e\u043f\u044b\u0442\u043e\u043a \u0434\u043b\u044f MeanShift/DBSCAN\n", "AP_ATTEMPTS        = 10  # \u0447\u0438\u0441\u043b\u043e \u0448\u0430\u0433\u043e\u0432 \u0431\u0438\u043d\u0430\u0440\u043d\u043e\u0433\u043e \u043f\u043e\u0438\u0441\u043a\u0430 \u0434\u043b\u044f AP\n", "DAMPING_AP         = 0.9"]}, {"cell_type": "markdown", "metadata": {}, "source": ["=== \u0424\u0443\u043d\u043a\u0446\u0438\u0438 \u043e\u043a\u0440\u0443\u0436\u0435\u043d\u0438\u044f \u0438 \u0443\u0442\u0438\u043b\u0438\u0442\u044b ==="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def setup_environment():\n", "    os.makedirs(PLOTS_DIR, exist_ok=True)\n", "    plt.style.use('seaborn-v0_8')\n", "    sns.set_theme(style=\"whitegrid\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def sanitize_filename(name: str) -> str:\n", "    return re.sub(r'[<>:\"/\\\\|?*]', '_', name)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def save_plot(fig, filename: str):\n", "    safe = sanitize_filename(filename)\n", "    path = os.path.join(PLOTS_DIR, safe)\n", "    fig.savefig(path, bbox_inches='tight')\n", "    plt.close(fig)\n", "    print(f\"\u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d \u0433\u0440\u0430\u0444\u0438\u043a: {safe}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["=== \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0438 \u043f\u0440\u0435\u043f\u0440\u043e\u0446\u0435\u0441\u0441\u0438\u043d\u0433 \u0434\u0430\u043d\u043d\u044b\u0445 ==="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def remove_highly_correlated_features(X: pd.DataFrame) -> pd.DataFrame:\n", "    corr = X.corr().abs()\n", "    upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n", "    to_drop = [c for c in upper.columns if any(upper[c] > CORR_THRESHOLD)]\n", "    if to_drop:\n", "        print(f\"\u0423\u0434\u0430\u043b\u0435\u043d\u044b \u0432\u044b\u0441\u043e\u043a\u043e\u043a\u043e\u0440\u0440\u0435\u043b\u0438\u0440\u043e\u0432\u0430\u043d\u043d\u044b\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u0438: {len(to_drop)}\")\n", "        return X.drop(columns=to_drop)\n", "    return X"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_and_preprocess(path: str):\n", "    df = pd.read_parquet(path)\n", "    y = df[\"Label\"]\n", "    X = df.drop(columns=[\"Label\"])\n", "    X = remove_highly_correlated_features(X)\n", "    scaler = StandardScaler()\n", "    X_scaled = scaler.fit_transform(X)\n", "    print(f\"\\n\u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u043e \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432: {X.shape[1]}\")\n", "    return X_scaled, y, X"]}, {"cell_type": "markdown", "metadata": {}, "source": ["=== EDA ==="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def explore_data(X: pd.DataFrame, y: pd.Series):\n", "    print(\"\\n=== \u0410\u043d\u0430\u043b\u0438\u0437 \u0434\u0430\u043d\u043d\u044b\u0445 (EDA) ===\")\n", "    print(f\"\u041e\u0431\u0440\u0430\u0437\u0446\u043e\u0432: {X.shape[0]}, \u041f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432: {X.shape[1]}\")\n", "    print(\"\u041a\u043b\u0430\u0441\u0441\u044b:\", list(np.unique(y)))\n", "    # \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043a\u043b\u0430\u0441\u0441\u043e\u0432\n", "    fig, ax = plt.subplots(figsize=(8,4))\n", "    y.value_counts(normalize=True).plot(kind='bar', ax=ax)\n", "    ax.set_title(\"\u0420\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u0435 \u043a\u043b\u0430\u0441\u0441\u043e\u0432\")\n", "    save_plot(fig, \"class_distribution.png\")\n", "    # \u043a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u043e\u043d\u043d\u0430\u044f \u043c\u0430\u0442\u0440\u0438\u0446\u0430\n", "    fig, ax = plt.subplots(figsize=(12,10))\n", "    sns.heatmap(X.corr(), cmap='coolwarm', center=0, ax=ax)\n", "    ax.set_title(\"\u041a\u043e\u0440\u0440\u0435\u043b\u044f\u0446\u0438\u043e\u043d\u043d\u0430\u044f \u043c\u0430\u0442\u0440\u0438\u0446\u0430 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\")\n", "    save_plot(fig, \"correlation_matrix.png\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["=== \u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f t-SNE ==="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_tsne(X: np.ndarray, labels, title: str, filename: str):\n", "    labels_arr = labels.values if hasattr(labels, 'values') else np.array(labels)\n", "    # \u043f\u043e\u0434\u0432\u044b\u0431\u043e\u0440\u043a\u0430 \u0434\u043b\u044f \u0443\u0441\u043a\u043e\u0440\u0435\u043d\u0438\u044f\n", "    if X.shape[0] > TSNE_SAMPLE_SIZE:\n", "        idx = np.random.choice(X.shape[0], TSNE_SAMPLE_SIZE, replace=False)\n", "        X_s, lbl_s = X[idx], labels_arr[idx]\n", "    else:\n", "        X_s, lbl_s = X, labels_arr\n", "    emb = TSNE(\n", "        n_components=2,\n", "        random_state=RANDOM_STATE,\n", "        perplexity=30,\n", "        max_iter=1000\n", "    ).fit_transform(X_s)\n", "    df2 = pd.DataFrame({\"C1\": emb[:,0], \"C2\": emb[:,1], \"label\": lbl_s})\n", "    fig, ax = plt.subplots(figsize=(8,6))\n", "    sns.scatterplot(data=df2, x=\"C1\", y=\"C2\", hue=\"label\", palette=\"deep\",\n", "                    s=40, alpha=0.8, edgecolor=\"k\", ax=ax)\n", "    ax.set_title(title)\n", "    save_plot(fig, filename)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["=== DBSCAN ==="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def run_dbscan(X: np.ndarray, y: pd.Series) -> np.ndarray:\n", "    print(\"\\n=== DBSCAN ===\")\n", "    # \u043f\u043e\u0434\u0431\u043e\u0440 eps \u0447\u0435\u0440\u0435\u0437 KneeLocator\n", "    nbrs = NearestNeighbors(n_neighbors=5).fit(X)\n", "    dists = np.sort(nbrs.kneighbors(X)[0][:, -1])\n", "    kl = KneeLocator(range(len(dists)), dists, curve='convex', direction='increasing')\n", "    # eps = dists[kl.knee] if kl.knee else np.median(dists)\n", "    eps = 0.5\n", "    print(f\"\u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c eps = {eps:.4f}\")\n", "    best_score, best_labels, best_params = -1, None, None\n", "    for i in range(MS_DBSCAN_ATTEMPTS):\n", "        ms = 5 + 2*i\n", "        model = DBSCAN(eps=eps, min_samples=ms).fit(X)\n", "        lbl = model.labels_\n", "        mask = lbl != -1\n", "        score = adjusted_rand_score(y[mask], lbl[mask])\n", "        print(f\"\u041f\u043e\u043f\u044b\u0442\u043a\u0430 {i+1}: min_samples={ms}, eps={eps:.4f}\\n  Rand Index={score:.4f}\")\n", "        if score > best_score:\n", "            best_score, best_labels, best_params = score, lbl, (ms, eps)\n", "        eps *= 1.5\n", "    print(f\"\u041b\u0443\u0447\u0448\u0438\u0439 Rand Index={best_score:.4f} \u043f\u0440\u0438 min_samples={best_params[0]} \u0438 eps={best_params[1]:.4f}\")\n", "    plot_tsne(X, best_labels, \"DBSCAN Clusters\", \"tsne_dbscan.png\")\n", "    return best_labels"]}, {"cell_type": "markdown", "metadata": {}, "source": ["=== MeanShift ==="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def run_meanshift(X: np.ndarray, y: pd.Series) -> np.ndarray:\n", "    print(\"\\n=== MeanShift ===\")\n", "    best_score, best_labels, best_bw = -1, None, None\n", "    bw = estimate_bandwidth(X, quantile=0.2)\n", "    for i in range(MS_DBSCAN_ATTEMPTS):\n", "        model = MeanShift(bandwidth=bw).fit(X)\n", "        lbl = model.labels_\n", "        mask = lbl != -1\n", "        score = adjusted_rand_score(y[mask], lbl[mask])\n", "        print(f\"\u041f\u043e\u043f\u044b\u0442\u043a\u0430 {i+1}: bandwidth={bw:.4f}\\n  Rand Index={score:.4f}\")\n", "        if score > best_score:\n", "            best_score, best_labels, best_bw = score, lbl, bw\n", "        bw *= 1.5\n", "    print(f\"\u041b\u0443\u0447\u0448\u0438\u0439 Rand Index={best_score:.4f} \u043f\u0440\u0438 bandwidth={best_bw:.4f}\")\n", "    plot_tsne(X, best_labels, \"MeanShift Clusters\", \"tsne_meanshift.png\")\n", "    return best_labels"]}, {"cell_type": "markdown", "metadata": {}, "source": ["=== Affinity Propagation ==="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def run_affinity(X: np.ndarray, y: pd.Series) -> np.ndarray:\n", "    print(\"\\n=== Affinity Propagation ===\")\n", "    sim = -euclidean_distances(X)\n", "    low, high = sim.min()*2, np.median(sim)\n", "    best_score, best_labels, best_pref = -1, None, None\n", "    for i in range(AP_ATTEMPTS):\n", "        pref = (low + high) / 2\n", "        model = AffinityPropagation(\n", "            damping=DAMPING_AP,\n", "            preference=pref,\n", "            max_iter=500,\n", "            convergence_iter=30,\n", "            random_state=RANDOM_STATE\n", "        ).fit(X)\n", "        lbl = model.labels_\n", "        mask = lbl != -1\n", "        ncls = len(np.unique(lbl[mask]))\n", "        score = adjusted_rand_score(y[mask], lbl[mask])\n", "        print(f\"\u041f\u043e\u043f\u044b\u0442\u043a\u0430 {i+1}: preference={pref:.2f}\\n  Rand Index={score:.4f}\")\n", "        if score > best_score:\n", "            best_score, best_labels, best_pref = score, lbl, pref\n", "        high = pref\n", "    print(f\"Rand Index={best_score:.4f} \u043f\u0440\u0438 preference={best_pref:.2f}\")\n", "    plot_tsne(X, best_labels, \"AffinityClusters\", \"tsne_affinity.png\")\n", "    return best_labels"]}, {"cell_type": "markdown", "metadata": {}, "source": ["=== \u041e\u0441\u043d\u043e\u0432\u043d\u043e\u0439 \u0437\u0430\u043f\u0443\u0441\u043a ==="]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    setup_environment()\n", "    X_scaled, y, X_raw = load_and_preprocess(PARQUET_PATH)\n", "    explore_data(X_raw, y)\n", "    plot_tsne(X_scaled, y, \"t-SNE: \u0418\u0441\u0442\u0438\u043d\u043d\u044b\u0435 \u043c\u0435\u0442\u043a\u0438\", \"tsne_true_labels.png\")\n", "    lbl_ms = run_meanshift(X_scaled, y)\n", "    lbl_db = run_dbscan(X_scaled, y)\n", "    lbl_ap = run_affinity(X_scaled, y)\n", "    print(\"\\n=== \u0424\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0435 \u043c\u0435\u0442\u0440\u0438\u043a\u0438 ===\")\n", "    \n", "    # \u0421\u043e\u0431\u0438\u0440\u0430\u0435\u043c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u0432\u0441\u0435\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432\n", "    results = []\n", "    for name, lbl in [(\"MeanShift\", lbl_ms), (\"DBSCAN\", lbl_db), (\"Affinity Propagation\", lbl_ap)]:\n", "        mask = lbl != -1\n", "        if len(np.unique(lbl[mask])) < 2:\n", "            continue\n", "            \n", "        metrics = {\n", "            \"Algorithm\": name,\n", "            \"Silhouette\": silhouette_score(X_scaled[mask], lbl[mask]),\n", "            \"Davies-Bouldin\": davies_bouldin_score(X_scaled[mask], lbl[mask]),\n", "            \"Calinski-Harabasz\": calinski_harabasz_score(X_scaled[mask], lbl[mask]),\n", "            \"Rand Index\": adjusted_rand_score(y[mask], lbl[mask]),\n", "        }\n", "        results.append(metrics)\n", "    \n", "    # \u0421\u043e\u0437\u0434\u0430\u0435\u043c DataFrame \u0434\u043b\u044f \u043a\u0440\u0430\u0441\u0438\u0432\u043e\u0433\u043e \u0432\u044b\u0432\u043e\u0434\u0430\n", "    df_results = pd.DataFrame(results)\n", "    \n", "    # \u0412\u044b\u0432\u043e\u0434\u0438\u043c \u0442\u0430\u0431\u043b\u0438\u0446\u0443 \u0441 \u043c\u0435\u0442\u0440\u0438\u043a\u0430\u043c\u0438\n", "    print(\"\\n\u0421\u0440\u0430\u0432\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u0430\u044f \u0442\u0430\u0431\u043b\u0438\u0446\u0430 \u043c\u0435\u0442\u0440\u0438\u043a \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u0438\u0437\u0430\u0446\u0438\u0438:\")\n", "    print(df_results.to_string(index=False, float_format=\"{:.4f}\".format))\n", "    \n", "    # \u0410\u043d\u0430\u043b\u0438\u0437 \u043b\u0443\u0447\u0448\u0438\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432\n", "    if not df_results.empty:\n", "        best_rand = df_results.loc[df_results['Rand Index'].idxmax()]\n", "        best_silhouette = df_results.loc[df_results['Silhouette'].idxmax()]\n", "        \n", "        print(\"\\n=== \u0421\u0440\u0430\u0432\u043d\u0435\u043d\u0438\u0435 \u043b\u0443\u0447\u0448\u0438\u0445 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u043e\u0432 ===\")\n", "        print(f\"\u041b\u0443\u0447\u0448\u0438\u0439 \u043f\u043e Rand Index ({best_rand['Rand Index']:.4f}): {best_rand['Algorithm']}\")\n", "        print(f\"\\n\u041b\u0443\u0447\u0448\u0438\u0439 \u043f\u043e Silhouette Score ({best_silhouette['Silhouette']:.4f}): {best_silhouette['Algorithm']}\")\n", "        \n", "        if best_rand['Algorithm'] == best_silhouette['Algorithm']:\n", "            print(\"\\n\u0412\u044b\u0432\u043e\u0434: \u041e\u0434\u0438\u043d \u0438 \u0442\u043e\u0442 \u0436\u0435 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c \u043f\u043e\u043a\u0430\u0437\u0430\u043b \u043b\u0443\u0447\u0448\u0438\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u043f\u043e \u043e\u0431\u0435\u0438\u043c \u043c\u0435\u0442\u0440\u0438\u043a\u0430\u043c\")\n", "        else:\n", "            print(\"\\n\u0412\u044b\u0432\u043e\u0434: \u0420\u0430\u0437\u043d\u044b\u0435 \u0430\u043b\u0433\u043e\u0440\u0438\u0442\u043c\u044b \u043f\u043e\u043a\u0430\u0437\u0430\u043b\u0438 \u043b\u0443\u0447\u0448\u0438\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b \u043f\u043e \u0440\u0430\u0437\u043d\u044b\u043c \u043c\u0435\u0442\u0440\u0438\u043a\u0430\u043c\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}